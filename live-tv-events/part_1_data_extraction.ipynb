{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live TV Events Data Science Guides - Part 1: Data Extraction\n",
    "\n",
    "PredictHQâ€™s Live TV Events data includes viewership prediction for the seven top US leagues: NFL, NBA, NHL, MLB, D1 NCAA Basketball, D1 NCAA American Football, and MLS. Our TV viewership data is designed for data scientists to improve forecasting at the county and store level. This How to Series allows you to quickly extract the data (Part 1), explore the data (Part 2) and experiment with different aggregations (Part 3).  \n",
    "\n",
    "<b>A How To Guide to extracting data from PredictHQ's Live TV Events.</b>\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Access Token](#access_token)\n",
    "- [Support Function](#support_functions) \n",
    "- [SDK Parameters](#sdk_parameters)\n",
    "- [SDK Call](#sdk_call)\n",
    "- [Output Dataframe](#output_dataframe)\n",
    "- [Appendix - Finding County place_id](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google Colab uncomment the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !git clone https://github.com/predicthq/phq-data-science-docs.git\n",
    "# %cd phq-data-science-docs/live-tv-events\n",
    "# !pip install predicthq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running locally, set up a Python environment using ```requirements.txt``` shared alongside the notebook to install the required dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "from predicthq import Client\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='access_token'></a>\n",
    "## Access Token\n",
    "\n",
    "To query the API, you will need an access token. If you have previously used the PredictHQ API to search and use events, you may still need to create a new access token to query broadcasts.\n",
    "\n",
    "The following link will guide you through creating an account and access token. \n",
    "\n",
    " - https://docs.predicthq.com/guides/quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Access Token with own access token.\n",
    "ACCESS_TOKEN = 'REPLACE_WITH_ACCESS_TOKEN'\n",
    "phq = Client(access_token=ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live TV Events data is available through the Broadcasts API.\n",
    "\n",
    "#### Events Coverage\n",
    "Broadcasts API returns each live sports broadcast for the following seven sports leagues in the US: \n",
    "\n",
    "- NFL\n",
    "- NBA\n",
    "- NHL\n",
    "- MLB\n",
    "- D1 NCAA Basketball\n",
    "- D1 NCAA American Football\n",
    "- MLS\n",
    "\n",
    "(Only live games are included. There are no replays.)\n",
    "\n",
    "#### Spacial Granularity\n",
    "\n",
    "Data is available for the United States at a granularity of county level. \n",
    "\n",
    "#### Features\n",
    "\n",
    "Each broadcast is provided with predicted viewership at the US county level. Additional data is available about the event, such as physical location and duration.\n",
    "\n",
    "#### Date Availablility\n",
    "\n",
    "January 1, 2018 to 2 weeks into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='support_functions'></a>\n",
    "## Support Functions\n",
    "\n",
    "Each broadcast relates to a physical sports event from the PredictHQ events knowledge graph. Additional data about the actual event is also returned. For example: the league and sport of the broadcast are included within the labels field. The following functions make it easier to extract the sport and league for each broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_matching_label(event_labels, labels_to_match):\n",
    "    '''\n",
    "    For each broadcast the league and sport type need to be\n",
    "    extracted. These labels are extracted from the labels.\n",
    "    As the order of the labels varies this look up is\n",
    "    required to compare to the frozenset of options.\n",
    "    '''\n",
    "    for label in labels_to_match:\n",
    "        if label in event_labels:\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "\n",
    "SPORTS = frozenset([\n",
    "        'american-football',\n",
    "        'baseball',\n",
    "        'basketball',\n",
    "        'ice-hockey',\n",
    "        'soccer',\n",
    "    ])\n",
    "LEAGUES = frozenset([\n",
    "        'mlb',\n",
    "        'mls',\n",
    "        'nba',\n",
    "        'ncaa',\n",
    "        'nfl',\n",
    "        'nhl',\n",
    "    ])\n",
    "\n",
    "def convert_timezone(row):\n",
    "    '''Convert event predicted end time to \n",
    "    broadcast location timezone from the event timezone.\n",
    "    '''\n",
    "    event_end_naive = row['dates_event']['predicted_end_local']\n",
    "    event_timezone = pytz.timezone(row['dates_event']['timezone'])\n",
    "\n",
    "    event_end_localtime= event_timezone.localize(event_end_naive, is_dst=None)\n",
    "    event_end_utc = event_end_localtime.astimezone(pytz.utc)\n",
    "\n",
    "    broadcast_timezone = row['dates_broadcast']['timezone']\n",
    "    broadcast_end_localtime = event_end_utc.astimezone(pytz.timezone(broadcast_timezone))\n",
    "    row['predicted_end_time_broadcast_local'] = broadcast_end_localtime.replace(tzinfo=None)\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk_parameters'></a>\n",
    "## SDK parameters\n",
    "\n",
    "We will create a dictionary of the key parameters and walk through each of the settings to use in the SDK call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " parameters_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewership Limits ```phq_viewership__gte=100```\n",
    "  -  We recommend filtering for broadcasts with a viewership greater than or equal to 100. This removes the smallest, noisiest broadcast predictions. This will remove a  number of broadcasts. This is customisable to your use case.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update(phq_viewership__gte=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Limits ```start={'gte': '2019-01-01', 'lte':'2021-01-15'}```\n",
    " - To define the period of time for which broadcasts will be returned set the greater than or equal `gte` and less than or equal `lte` parameters for start. This will select all broadcasts that start within this period.\n",
    " \n",
    " \n",
    "Bear in mind that you could use either of these parameters depending on your time period of interest:\n",
    "\n",
    "```gte - Greater than or equal.``` <br>\n",
    "```gt - Greater than.```<br>\n",
    "```lte - Less than or equal.```<br>\n",
    "```lt - Less than.```<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your chosen start and end date.\n",
    "START_DATE = '2019-01-01'\n",
    "END_DATE = '2021-02-14'\n",
    "parameters_dict.update(start={'gte': START_DATE, 'lte':END_DATE}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limits  ```limit=500```\n",
    "\n",
    " - When pulling historical data for a large time period many results are returned. To speed up the execution set ```limit``` to the highest available setting (500). By doing this each call to the API returns 500 results and this will speed up processing large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update(limit=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Limits ```location__place_id=4888671```\n",
    "\n",
    " - To define which counties to select use the `location__place_id` and the place_id of the county. The place_id of the county is the geonames id of the county. In the [Appendix](#appendix) is a guide as to how to find which county to use dependant  on the locations of your business. \n",
    " \n",
    "For the SDK call, you can specify your own counties of interest. However here are four default counties to query as an example:\n",
    "\n",
    " - 'Clark County, Nevada': 5501879\n",
    "\n",
    " - 'Los Angeles County, California': 5368381\n",
    "\n",
    " - 'Cook County, Chicago, Illinois': 4888671\n",
    "\n",
    " - 'Harris County, Houston, Texas': 4696376\n",
    " \n",
    " \n",
    "The place_id will be set within the SDK call as a loop through the counties of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run for your own counties of interest - replace these ids.\n",
    "LIST_OF_COUNTIES = [5501879] # 5368381, 4888671, 4696376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phq_viewership__gte': 100,\n",
       " 'start': {'gte': '2019-01-01', 'lte': '2021-02-14'},\n",
       " 'limit': 500}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the place_id is set within the loop below.\n",
    "parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk_call'></a>\n",
    "## SDK Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the call to the broadcasts API for each county of interest.\n",
    "\n",
    "Not all broadcasts will be returned for each county. For example if a county has low broadcast coverage (<45% of the county population have access to the broadcast) the broadcast will be removed. Other reasons a broadcast may not appear could be if the phq_viewership setting excludes any broadcasts with low numbers. Certain sports events in certain counties are forecast to have low viewership. \n",
    "\n",
    "The data for each county is saved to csv as an example output. This can be adjusted to work with your own data pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each county\n",
    "for place_id in LIST_OF_COUNTIES:\n",
    "    \n",
    "    parameters_dict.update(location__place_id=place_id) \n",
    "    \n",
    "    search_results = phq.broadcasts.search(parameters_dict).iter_all()\n",
    "\n",
    "    search_results = [result.to_dict() for result in search_results]\n",
    "\n",
    "    df = pd.DataFrame(search_results)\n",
    "\n",
    "    # Extract out additional information\n",
    "    # 'event' stores the additional data about the physical event\n",
    "    df = df.merge(df['event'].apply(pd.Series),\n",
    "                  left_index=True,\n",
    "                  right_index=True,\n",
    "                  suffixes=('_broadcast', '_event'))\n",
    "\n",
    "    # Extract sport and league from the labels in the nested event data.\n",
    "    df['sport'] = df.labels.apply(_extract_matching_label, args=(SPORTS,))\n",
    "    df['league'] = df.labels.apply(_extract_matching_label, args=(LEAGUES,))\n",
    "\n",
    "    df['local_start_date'] = (df.dates_broadcast\n",
    "                                .apply(\n",
    "                                        lambda start_dt:\n",
    "                                        (start_dt['start_local']).date()\n",
    "                                       )\n",
    "                              )\n",
    "\n",
    "    df['county_place_id'] = (df.location_broadcast\n",
    "                               .apply(\n",
    "                                       lambda location:\n",
    "                                       location['places'][0]['place_id']\n",
    "                                     )\n",
    "                             )\n",
    "\n",
    "    df['local_start_datetime'] = (df.dates_broadcast\n",
    "                                    .apply(\n",
    "                                            lambda start_dt:\n",
    "                                            (start_dt['start_local'])\n",
    "                                          )\n",
    "                                  )\n",
    "\n",
    "    # Check for any events without a predicted end time.\n",
    "    # All broadcasts are expected to have a predicted end time\n",
    "    broadcast_id_no_endtime = [row['broadcast_id'] for _, row in df.iterrows() \\\n",
    "                               if not row.get('dates_event', {}).get('predicted_end_local')]\n",
    "    # Remove any broadcasts without a predicted end time.\n",
    "    df = df[~df['broadcast_id'].isin(broadcast_id_no_endtime)]\n",
    "\n",
    "    # Convert the predicted end time of the event to broadcast timezone.\n",
    "    df = df.apply(convert_timezone, axis=1)\n",
    "\n",
    "    df['sport_league'] = df['sport'] + '_' + df['league']\n",
    "    # Calculate the duration of the broadcast. \n",
    "    df['duration'] = df['predicted_end_time_broadcast_local'] - df['local_start_datetime']\n",
    "    df['duration_hours'] = df['duration'].dt.seconds/(60*60)\n",
    "    df['total_viewing'] = df['duration_hours'] * df['phq_viewership']\n",
    "    \n",
    "    # Save dataframe to csv\n",
    "    df.to_csv('data/tv_events_data/{}_county_raw.csv'.format(place_id),\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned data is at the broadcast level. Each broadcast for the selected county in the selected county is returned that met the parameters of the SDK call. In Part 2 of this How to Series we will explore this data to understand the key trends. In Part 3 we'll prepare features to be used in a forecasting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='output_dataframe'></a>\n",
    "## Output Dataframe\n",
    "\n",
    "It is important to understand the output data. \n",
    "\n",
    "There is one key aspect to be familiar with. This is which data fields relate to the broadcast and which fields relate to the physical sports event that the broadcast is showing. The data that was extracted out of the ```event``` are all related to the actual physical event.  \n",
    "\n",
    "For absolute clarity in the returned dataframe, the following columns relate to the broadcast:\n",
    "\n",
    "- broadcast_id\n",
    "- updated\n",
    "- dates_broadcast\n",
    "- location_broadcast\n",
    "- phq_viewership\n",
    "- record_status\n",
    "- broadcast_status\n",
    "- local_start_date\n",
    "- local_start_datetime\n",
    "- county_place_id\n",
    "- predicted_end_time_broadcast_local\n",
    "- total_viewing\n",
    "\n",
    "\n",
    "And the following columns relate the the actual physical event (Note: many of these are relevent additional data about the broadcast):\n",
    "\n",
    "- event\n",
    "- event_id\n",
    "- title \n",
    "- category \n",
    "- labels\n",
    "- dates_event\n",
    "- location_event\n",
    "- entities \n",
    "- phq_attendance\n",
    "- phq_rank\n",
    "- local_rank\n",
    "- aviation_rank\n",
    "- sport\n",
    "- league\n",
    "- duration\n",
    "- duration_hours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>broadcast_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>dates_broadcast</th>\n",
       "      <th>location_broadcast</th>\n",
       "      <th>phq_viewership</th>\n",
       "      <th>record_status</th>\n",
       "      <th>broadcast_status</th>\n",
       "      <th>event</th>\n",
       "      <th>event_id</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>sport</th>\n",
       "      <th>league</th>\n",
       "      <th>local_start_date</th>\n",
       "      <th>county_place_id</th>\n",
       "      <th>local_start_datetime</th>\n",
       "      <th>predicted_end_time_broadcast_local</th>\n",
       "      <th>sport_league</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>total_viewing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8Cy3b48jHZAPdxbDRbkaQk</td>\n",
       "      <td>2020-12-03 10:08:04+00:00</td>\n",
       "      <td>{'start': 2019-01-01 00:00:00+00:00, 'start_lo...</td>\n",
       "      <td>{'geopoint': {'lat': 36.2152, 'lon': -115.0135...</td>\n",
       "      <td>68084</td>\n",
       "      <td>active</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>{'event_id': 'S8F7FMsKiiU4q8UF67', 'title': 'N...</td>\n",
       "      <td>S8F7FMsKiiU4q8UF67</td>\n",
       "      <td>Northwestern Wildcats vs Utah Utes</td>\n",
       "      <td>...</td>\n",
       "      <td>american-football</td>\n",
       "      <td>ncaa</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>5501879</td>\n",
       "      <td>2018-12-31 16:00:00</td>\n",
       "      <td>2018-12-31 19:20:00</td>\n",
       "      <td>american-football_ncaa</td>\n",
       "      <td>0 days 03:20:00</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>226946.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93LTY9p25MRrj39sGYxepc</td>\n",
       "      <td>2020-12-05 05:41:16+00:00</td>\n",
       "      <td>{'start': 2019-01-01 00:00:00+00:00, 'start_lo...</td>\n",
       "      <td>{'geopoint': {'lat': 36.2152, 'lon': -115.0135...</td>\n",
       "      <td>18805</td>\n",
       "      <td>active</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>{'event_id': 'usqZVdBrXwBLVQfsRG', 'title': 'B...</td>\n",
       "      <td>usqZVdBrXwBLVQfsRG</td>\n",
       "      <td>Boston Celtics vs San Antonio Spurs</td>\n",
       "      <td>...</td>\n",
       "      <td>basketball</td>\n",
       "      <td>nba</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>5501879</td>\n",
       "      <td>2018-12-31 16:00:00</td>\n",
       "      <td>2018-12-31 18:20:00</td>\n",
       "      <td>basketball_nba</td>\n",
       "      <td>0 days 02:20:00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>43878.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             broadcast_id                   updated  \\\n",
       "0  8Cy3b48jHZAPdxbDRbkaQk 2020-12-03 10:08:04+00:00   \n",
       "1  93LTY9p25MRrj39sGYxepc 2020-12-05 05:41:16+00:00   \n",
       "\n",
       "                                     dates_broadcast  \\\n",
       "0  {'start': 2019-01-01 00:00:00+00:00, 'start_lo...   \n",
       "1  {'start': 2019-01-01 00:00:00+00:00, 'start_lo...   \n",
       "\n",
       "                                  location_broadcast  phq_viewership  \\\n",
       "0  {'geopoint': {'lat': 36.2152, 'lon': -115.0135...           68084   \n",
       "1  {'geopoint': {'lat': 36.2152, 'lon': -115.0135...           18805   \n",
       "\n",
       "  record_status broadcast_status  \\\n",
       "0        active        scheduled   \n",
       "1        active        scheduled   \n",
       "\n",
       "                                               event            event_id  \\\n",
       "0  {'event_id': 'S8F7FMsKiiU4q8UF67', 'title': 'N...  S8F7FMsKiiU4q8UF67   \n",
       "1  {'event_id': 'usqZVdBrXwBLVQfsRG', 'title': 'B...  usqZVdBrXwBLVQfsRG   \n",
       "\n",
       "                                 title  ...              sport league  \\\n",
       "0   Northwestern Wildcats vs Utah Utes  ...  american-football   ncaa   \n",
       "1  Boston Celtics vs San Antonio Spurs  ...         basketball    nba   \n",
       "\n",
       "  local_start_date county_place_id local_start_datetime  \\\n",
       "0       2018-12-31         5501879  2018-12-31 16:00:00   \n",
       "1       2018-12-31         5501879  2018-12-31 16:00:00   \n",
       "\n",
       "   predicted_end_time_broadcast_local            sport_league        duration  \\\n",
       "0                 2018-12-31 19:20:00  american-football_ncaa 0 days 03:20:00   \n",
       "1                 2018-12-31 18:20:00          basketball_nba 0 days 02:20:00   \n",
       "\n",
       "   duration_hours  total_viewing  \n",
       "0        3.333333  226946.666667  \n",
       "1        2.333333   43878.333333  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix'></a>\n",
    "## Appendix: Finding County ```place_id``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a guide on how to link store locations to the county ```place_id``` dependant on the geodata you have available for your locations. \n",
    "\n",
    " - Location Longitude and Latitude\n",
    " - Location FIPS code\n",
    " \n",
    "PredictHQ uses the geonames places convention https://www.geonames.org/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Location Longitude and Latitude\n",
    "\n",
    "By using PredictHQ Places API you can find the county for a specific latitude and longitude. By calling the API against the longitude and latitude, and setting ```type``` to ```county```the API will return the most relevent counties. Taking the top county will provide the county the location is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two example locations.\n",
    "locations = [[40.66677, -73.88236], [33.95345, -118.3392]]\n",
    "\n",
    "location_county_lookup = pd.DataFrame()\n",
    "\n",
    "for location in locations:\n",
    "    response = requests.get(\n",
    "        url=\"https://api.predicthq.com/v1/places/\",\n",
    "        headers={\n",
    "          \"Authorization\": \"Bearer {}\".format(ACCESS_TOKEN),\n",
    "          \"Accept\": \"application/json\"\n",
    "        },\n",
    "        params={\n",
    "            \"location\": \"@{},{}\".format(location[0], location[1]),\n",
    "            \"type\": \"county\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    data = response.json()\n",
    "    df = pd.json_normalize(data['results'])\n",
    "    location_county_lookup = location_county_lookup.append(df.iloc[0],\n",
    "                                                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_alpha2</th>\n",
       "      <th>country_alpha3</th>\n",
       "      <th>county</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>region</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>5133268</td>\n",
       "      <td>[-73.83875, 40.65749]</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>New York</td>\n",
       "      <td>county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>5368381</td>\n",
       "      <td>[-118.26102, 34.19801]</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>California</td>\n",
       "      <td>county</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country country_alpha2 country_alpha3              county       id  \\\n",
       "0  United States             US            USA       Queens County  5133268   \n",
       "1  United States             US            USA  Los Angeles County  5368381   \n",
       "\n",
       "                 location                name      region    type  \n",
       "0   [-73.83875, 40.65749]       Queens County    New York  county  \n",
       "1  [-118.26102, 34.19801]  Los Angeles County  California  county  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_county_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Location FIPS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoname_id</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4047434</td>\n",
       "      <td>Russell County</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4048080</td>\n",
       "      <td>Long County</td>\n",
       "      <td>13183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4048522</td>\n",
       "      <td>Boone County</td>\n",
       "      <td>21015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4048572</td>\n",
       "      <td>Rowan County</td>\n",
       "      <td>21205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4049189</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geoname_id     county_name  county_fips\n",
       "0     4047434  Russell County         1113\n",
       "1     4048080     Long County        13183\n",
       "2     4048522    Boone County        21015\n",
       "3     4048572    Rowan County        21205\n",
       "4     4049189     Bibb County         1007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We provide a lookup between FIPS code and place_id. (geoname_id = place_id)\n",
    "mapping = pd.read_csv('data/geo_data/geoname_to_fips_mapping.csv')\n",
    "mapping.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_envtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
